%%%%% The Problem %%%%% and %%%%% Related Work %%%%%

\chapter{State of the Art in Computer Science Didactics} \label{ch_theory}

In relation to systems, didactic literature recommends examining multiple layers of a system, for students to better understand the material. This concept (later called \emph{Sichtenwechsel} for lack of a better fitting English term) is introduced in \ref{ssc_sichtenwechsel} and is considered a foundational idea that should be exploited in teaching as well as also taught explicitly (elaborated in \ref{ssc_fundamentale_ideen}).

Learning to handle complex systems is at the core of what happens in many subjects in school (high school and beyond). With relation to computer science, this is asked for in particular when teaching students computational thinking (see \ref{ssc_ct}). One aspect that we feel is particularly important in this regard is the fact that systems can rarely be separated into independently investigable layers in a clean way -- or in other words: many abstractions involved in layering complex systems leak (see \ref{ssc_leaky_abstractions}).

When multiple abstraction levels are taught together, common approaches consist in doing so either bottom up (\ref{ssc_bottom_up}) or top down (\ref{ssc_top_down}), showing how to potentially proceed.

In our experience, one thing high school students like particularly well during their computer science curriculum is programming (which is reflected in the student feedback discussed in chapter \ref{ch_practice}). Therefore, we want to merge the discussion on multitier abstractions and abstraction leaks with programming. However, existing \acp{IDE} as discussed in \ref{ssc_ides} only support this up to a point we found insufficient. Thus, we set out to create our own teaching environment (presented in chapter \ref{ch_pa}).

Finally, this environment for combining programming with a view on different abstraction levels should also adhere to current didactic best practices, mainly manageability (\ref{ssc_manageability}), liveness, and explorability (\ref{ssc_exploration}).



\section{Didactic Approaches} \label{sc_didactic}

Traditional introductions to programming usually focus on a single programming language, its syntax, and the available semantics -- introducing them iteratively and practicing each element with basic exercises. Hartinger \eg introduces most of Python in this way, so that it can later be used for scientific calculations \cite{Har20}. 

This traditional introduction works mainly on the level of the programming language, just barely mentioning a simplified memory model (p.\,31) and binary encoding (pp.\,114--115). Interestingly, it does not assume an \ac{IDE} but instead very briefly introduces the command line and the Python \ac{REPL}. Even though in that way, files are not guaranteed to be UTF-8 encoded (as examples assume, cf. p.\,118), encodings are not mentioned beyond pure ASCII, and the Python interpreter is just briefly characterized as ``the program that translates source code into electronic instructions''\footnote{German original: ''[\dots] das Programm, das den Programmcode in Elektronik-Anweisungen übersetzt.''} in the preface.

While the needs of academic teaching and the form of semester courses with lectures and separate lab work tend to suggest such an approach, this is not a good fit with suggestions from current didactic literature \cite{Sch11, Mod16} (and even past texts \cite{Doy84}), as described in the following subsections.


\subsection{Foundational Ideas} \label{ssc_fundamentale_ideen}

Schubert and Schwill \cite{Sch11} base their didactic approach around the notion of foundational ideas (\emph{fundamentale Ideen}) derived from Jerome Bruner and Alfred Schreiber. A foundational idea is a concept that is deeply ingrained in a specific subject and without which the subject would lose part of its core. Additionally, they ask for a foundational idea to have the following properties (pp.\,64--65):
\begin{itemize}
\item Breadth: The concept is applicable not just in one specific context but can be used more generally.
\item Abundance: The concept encompasses sufficient substance so that it can be taught to beginners and experts alike.
\item Meaning: The concept is meaningful to the learner beyond the scope of a course.
\item Historical Relevance: The development of the concept can be observed historically, and the concept has remained relevant through time.
\end{itemize}

As such foundational ideas they list among many others the idea of modularization, the idea of layered architectures and the idea of encoding information (and as a special case: instructions).

As a consequence, they propose an introduction to programming by using several different programming languages along different paradigms: \eg Prolog as a declarative language (pp.\,91--104) and Python as an object-oriented language (pp.\,157--185), in order to better teach the foundational idea of Language and to demonstrate to students already at the level of instructions that the language chosen comes with inherent limitations in expressibility (p.\,154, comparing programming languages with natural languages and referring to Wittgenstein's philosophy of language).

Interestingly, they don't mention any lower-level language as an alternative, considering translations between different high-level languages to be sufficiently plausible to students, although the limitations of languages such as an Assembly variation might be just as plausible, if not more, due to a far less expressive command set.


\subsection{\emph{Sichtenwechsel}} \label{ssc_sichtenwechsel}

Consequently, Schubert and Schwill \cite{Sch11} propose to explicitly discuss the foundational idea of multitier architectures -- and that not only in the context of the networking stack and computer architecture (pp.\,113--116): They introduce the notion of \emph{Sichtenwechsel}, a change of perspective with relation to the current layer, which should help students better understand concepts of one layer by inspecting lower layers. As an example, they show a live model of a calculator app whose input is translated to both pseudo code and machine code (p.\,115); an environment for inspecting live Java objects (pp.\,208--209); or the Filius environment for inspecting a virtual computer network at its different layers (p.\,284, \cite{Gar15}).

They conclude that ``it was a fallacy to assume that students would be able to develop a working model of a computer [\dots] by designing small programs'' (p.\,213),\footnote{German original: ``Es erwies sich als Irrtum, dass Schüler beim Entwerfen kleiner Programme ein tragfähiges kognitives Modell vom Rechner oder von Informatiksystemen im Allgemeinen entwickeln.''} reinforcing the need for combining programming with computer architecture.

The same conclusion has been reached repeatedly, also \eg by Jaokar \cite[p.\,51]{Jao12} or Zhang \cite[p.\,407]{Zha19}.


\subsection{Computational Thinking} \label{ssc_ct}

Since other disciplines have started to rely on computers as more than glorified digital typewriters and filing cabinets, the notion of preparing students for work in academia and industry has shifted from teaching applications to teaching computational thinking. Lee \etal \cite{Lee20} have assembled case studies from schools where programming is used in physics, biology, chemistry and other sciences, linking it to the role that mathematics has had in the past centuries.

If students are to be able to solve problems in other domains using programming, simulations or data transformations, they must also be versed in dealing with different abstraction levels in order to connect the abilities of a computer with the subject at hand. Buitrago \etal \cite{Bui17} point out that students must in particular know the limits of computers and not attribute understanding and intelligence to them.

This has become an even more important matter with the recent rise of \acp{LLM} to being ubiquitously available. With \acp{LLM} available, computational thinking even refers back to programming: Martini \cite{Mar24} argues that with \acp{LLM} being able to write programs on their own, programming curricula have to be adjusted accordingly. However, students will still have to be able to understand the basics, in order to be able to instruct an \ac{LLM} towards a desired result. Also, recent studies seem to suggest that relying on \acp{LLM} for coding does not lead to better developer performance \cite{Bec25} nor to better code \cite{Moh25}, as cognitive offloading has been observed. This effect is likely even more pronounced for students, as getting quick results for simple tasks might lull them into overconfidence with relation to the available \ac{LLM}. As a consequence, the functioning and limits of \acp{LLM} must not only be taught as part of computational thinking but also be used as another example for examining different abstraction levels in a computer system.


\subsection{Teaching Bottom Up} \label{ssc_bottom_up}

Beyond suggesting to connect multiple abstraction levels in a \emph{Sichtenwechsel} (see \ref{ssc_sichtenwechsel}), general didactic literature does not offer more specific suggestions. There are, however, two readily available ways of dealing with abstraction levels: Either starting at the bottom and building abstractions on top; or starting at the most abstract and dissecting it into its more fundamental forms.

Starting at the bottom seems to be the conceptually sounder way and is \eg how Mathematics are taught. One rigorous implementation of this approach is offered by Nisan and Schocken \cite{Nis21}: They offer a course that starts with basic logic gates and builds out of them first the parts of and later a fully functioning, basic \acsu{CPU} for which they continue to develop a low-level and a high-level programming language until reaching the point where applications can be run on the developed hardware (this was originally dubbed as ``NAND to Tetris'').

Their motivation is similar to the motivation for this thesis: ``The most fundamental ideas [\dots] are now hidden under many layers of obscure interfaces'' (p.\,ix), which they set out to reveal. Since the course is taught at university with hundreds of students, one concession is hardware virtualization: The original logic gates are not built out of silicon or electronics but instead simulated in a portable Java app. This allows skipping intermediary steps and makes it possible to start the course at any desired level.

Since working with logic gates without seeing their eventual purpose may lack motivation, the course starts with an overview from the top, which also serves as the table of contents (pp.\,1--4, represented in figure \ref{fig_multitier} on page \pageref{fig_multitier}). With this, students keep in sight what they are working towards and can start connecting their own preexisting notions with the new material.


\subsection{Teaching Top Down} \label{ssc_top_down}

An alternative teaching approach starts directly with the students' experience, \eg at gaming \cite{Wei16}, art \cite{Rea14} or even toy houses requiring intruder alerts \cite{Mod16}, and starts exposing lower abstraction levels as required to gain more control (and understanding) as well as extending available capabilities.

One approach, which nowadays might already be considered rather traditional, starts with games: Weintrop and Wilensky \cite{Wei16} discuss a variety of games where programming plays a role in either shaping an avatar, improving its available actions or making it move altogether. Whereas such games are specifically created as pedagogical games, many other games have at least part of their logic implemented in scripting languages such as Lua \cite{Lua25}, which allows them to be modified by players. While the content involved is more complex, modifying or creating a game within still popular Roblox might also be sufficiently motivating.

While gaming works as an approach to programming, it is rarely used to inspect further layers in an educational context. Motivation for doing so is usually restricted to performance optimizations for game platform developers.

An alternative approach, which originally targeted art students but works well at high school as well, is proposed by Reas and Fry \cite{Rea14}: Starting from visual arts and extending the capabilities of the artist through digital means. While the involved programming language, Processing, will be discussed on its own merit in \ref{sc_processing}, their didactic approach is notable as well: A work of art on its own is something abstract that not only can be interpreted but also created. To (re)create it, various painting techniques are needed, which can be further broken down to basic movements. At this abstraction layer, they start with high-level programming primitives for creating basic shapes. This allows them to achieve pleasing visual results with just a few commands and initially barely any programming knowledge. Afterwards, the question of how to achieve more complex output is naturally motivated by the more complex works of art already discussed.

To achieve this, Reas and Fry \cite{Rea14} feature several chapters focused on exhibits of digital or hybrid art such as Manfred Mohr's \emph{Une esthétique programmée} or Steph Thirion's \emph{Eliss}.

Additionally, as art can be considered as individual expression, the parallel to programming as individual expression (as also proposed by Modrow and Strecker \cite{Mod16}) and programming as art is easily drawn: ``To use a tool on a computer, you need do little more than point and click; to create a tool, you must understand the arcane art of computer programming.'' (p.\,3). Finally, programmed art must not remain purely digital and can be extended to physical sculptures, for which at least some considerations about hardware can be introduced.

While in both approaches -- gaming and art --, stepping further down to lower abstraction levels is a possibility, only one or two such steps are naturally motivated from the source material. Nonetheless, in both cases a \emph{Sichtenwechsel} is possible.

As a side note: In high school courses spanning over one or even multiple years, either a top-down or a bottom-up approach could be implemented consistently. At university, with independent semester lectures being the standard, the focus usually lies on a single abstraction layer or picking out just a few. Courses as the one held by Nisan and Schocken \cite{Nis21} seem to be the exception. Arguably, computer science students should be able to better cope with such disparities, whereas a more coherent approach might be desirable at high school.


\subsection{Manageability} \label{ssc_manageability}

Modrow and Strecker \cite{Mod16} follow Schubert and Schwill \cite{Sch11} in also building upon the concept of foundational ideas. They do, however, propose to reduce their number significantly and focus on a few very general such ideas such as modelling, connectivity, digitization and algorithms (pp.\,27--37).\footnote{German original: ``Modellierbarkeit'', ``Vernetzbarkeit'', ``Digitalisierbarkeit'', ``Algorithmisierbarkeit''.} As a consequence, they propose to focus programming exposure for high school students on block-based programming languages such as MIT's Scratch\footnote{\emph{Cf.} \url{https://scratch.mit.edu/}.} or Berkeley's variant Snap!\footnote{\emph{Cf.} \url{https://snap.berkeley.edu/}.} (p.\,125).

Their reasoning for this is that students should not (yet) have to deal with syntax errors (as opposed to teaching these as suggested by Bouvier \etal \cite{Bou24}) and only have a manageable command palette.\footnote{Going even further, Asai \cite{Asa25} introduced a block-based environment based on OCaml which also inherently prevents scoping and type errors.} Furthermore, they note that block-based languages with free form layouting encourages students to build complex behavior from simple building blocks that can always be run and inspected individually (pp.\,184--185). This allows for a bottom-up development approach in which abstractions are incrementally developed out of basic command blocks, which they deem more suitable for students than starting development at the abstract algorithm.

While Modrow and Strecker suggest also including digital circuits in the curriculum as concrete examples of digitization (p.\,118), they seem content with programming them without inspecting the layers in between. From their foundational idea of connectivity, treating these layers could, however, still follow: If students are to see how hardware and software are connected -- and that such a connection is even possible --, intermediary steps between program and hardware must be explorable by students.

Following in these footsteps, Chiodini \etal \cite{Chi23} similarly state the following requirements for programming classes:
\begin{itemize}
\item Manageable complexity: \acp{IDE} and \acp{API} must not be unnecessarily complex so as to not confuse students.
\item Meaningful engagement: Samples and exercises should be introduced in such a way that it is clear what they refer to outside of class. Their usefulness shouldn't end with the exam.
\item Clean problem decomposition: Bottom-up development should be effortless and code should be composable with minimal changes required, if any.
\end{itemize}

The last point explicitly asks for a clean separation of abstraction levels, which might be an ideal to strive for but might not be realistically achievable (cf. \ref{ssc_leaky_abstractions}).


\subsection{Exploratory and Live Programming} \label{ssc_exploration}

Live programming refers to output and other intermediary products being adapted or recalculated every time source code changes, without requiring any explicit saving and/or rerunning by the programmer \cite{Rei18}. This gives students the quickest results, as else they might work on code too long without occasionally testing it if doing so requires additional interactions (for the same reason, many applications have switched to auto-saving instead of relying on users to do so manually from time to time). Live programming also gives students immediate feedback about their code and modifications.

Exploratory programming on the other hand refers to students exploring code and its effects by running and modifying it in order to build a mental model.\footnote{Usually, exploratory programming more broadly refers to programmers working without fully specified requirements and thus having to discover these through exploration of the problem space. In this thesis, we will, however, restrict usage of the term to the pedagogical setting.} Both Schubert and Schwill \cite[p.\,367]{Sch11} and Modrow and Strecker \cite[p.\,167]{Mod16} suggest exploratory programming to allow students to work at their own speed and depth: With shared examples, less experienced students can stay closer to the given -- simple but working -- code, while more experienced students can use their knowledge to test more complicated hypotheses.

While live programming requires explicit support from the programming environment (see \ref{ssc_ides}), exploratory programming is possible without it. In fact, Rein \etal \cite{Rei18} note that in literature these concepts are usually treated separately, with barely any intersection between the two concepts. Apps can better support exploration by at least providing a form of \ac{REPL}, which most scripting languages do, an interactive notebook (such as Jupyter or Lepiter, see \ref{sc_gt}), or a way of directly running any part of a program, as Scratch does (see \ref{ssc_manageability}).

The didactic reasons for using both live and exploratory programming also apply outside or pure programming, such as when inspecting and modifying live systems, networks, simulations, \etc



\section{Multitier Architectures / Abstractions} \label{sc_abstractions}

In order to handle complexities arising in both theoretical and practical computer science, subjects are split into multiple layers or tiers to be described, investigated and used separately.

Common multitier architectures taught at high school level are the networking stack (for manageability reasons rather the simplified four layered DoD architecture than the seven layered OSI model) or the software-hardware stack ranging from apps and hardware abstracting OS down to transistors consisting of \eg silicium atoms (see \cite{Oin25c} and figure \ref{fig_multitier}).

\begin{cfigure}[fig_multitier]{Multitier model of a computer system \cite[p.\,xii]{Nis21}.}
\input{diagrams/multitier}
\end{cfigure}

Ideally, in such architectures all layers above the layer to be investigated can be ignored (beyond what the layer will be used for) and all the layers below can be abstracted away into a nicely defined interface.

In this regard, programming should be possible independently of either hardware or operating system, in the same way that natural languages can be taught independently of a specific body or mind of the students.

However, this analogy shows that even in computer science the philosophical mind-body problem persists, albeit in a different form: ``At the grossest physical level, a computer process is a series of changes in the state of a machine'' \cite[p.\,12]{Col99}. In contrast to the human mind, where the interaction between objectively observable brain matter and subjective thought is at the core of an ongoing philosophical and neuroscientific debate, in computer science this duality of having electrical current on the one hand and a running program on the other is decomposable all the way through.

And as has been shown above, didactic literature suggests that this feature should be discussed, as this is a foundational idea of computer science.


\subsection{Leaky Abstractions} \label{ssc_leaky_abstractions}

In his article ``The Law of Leaky Abstractions'', Spolsky \cite{Spo02} introduces the concept of \emph{leaky abstractions}, claiming that for all non-trivial architectures, details of lower layers are to some degree bound to bleed through to upper layers. In other words, in practice complex interfaces tend to be incomplete or ``leaky''.

In teaching computer science, such leaky abstractions occur repeatedly, \eg when an app doesn't run on a different device (with either the OS or the processor architecture leaking); or when a document seemingly can't be saved (with either the file system or differences between apps leaking).

More specifically in programming, there are several ways of abstracting away technical details:

\begin{itemize}
\item Programming instructions consist of source code, which consists of encoded bits, which are stored in memory or on a drive.
\item Source code consists of tokens, which are usually parsed into an \ac{AST}, which are either directly or via \ac{IR} translated into machine code, which runs on a virtual or actual machine.
\item When programming instructions are executed through the above abstractions, variable values are encoded and stored in memory, function calls are traced through a call stack, input state is continually mapped into memory and output is generated in several forms -- where \eg textual output causes a font renderer to interpret glyph instructions for every character; or graphical output is anti-aliased before any pixel data is produced.
\end{itemize}

Of these different layers, students usually focus on turning instructions into source code and then checking the program's output -- or any error messages produced by the compiler or interpreter (see section \ref{sc_didactic}). Still, several of the lower-level abstractions might leak through, such as:

\begin{itemize}
\item Missing a stop condition in a recursive function leads to a cryptic ``Stack overflow'' error -- leaking information about the call stack.
\item If a program outputs emojis, they might look notably differently in source code and output -- leaking font rendering.
\item Similarly, programs containing emojis might have the emojis garbled depending on the app used for inspecting the source code -- leaking text encoding.
\item If a program contains an endless loop, there might be neither an error message nor output, so that it might wrongly seem that the computer isn't doing anything. This isn't an abstraction leak in the above sense but a related student misconception.
\end{itemize}

Besides the rather easily observable abstraction leaks mentioned above, the issue itself might also have to be discussed, since recently one class of leaky abstractions has been shown to be security critical: timing attacks. Since programs might be compiled differently and optimized differently and run on different hardware, runtime timing is not considered to be inherent to a particular piece of source code.\footnote{At least beyond generic complexity considerations on an algorithmic level.}

In cryptography, timing attacks have been successfully used for extracting passwords from insufficiently protected webservers \cite{Por18}. More recently, another class of timing attacks taking advantage of modern \ac{CPU}'s branch prediction optimizations has been demonstrated \cite{Koc19}. In the latter case, an implementation detail of the \ac{CPU} managed to leak. And in both cases, at least implementors of cryptographic programs must be aware of lower abstraction levels.

Further examples of leaky abstractions are discussed by Egger \cite{Egg24} and many others \cite{Nat25, Kan25}. These show that knowledge of lower layers is particularly important for developers of compilers and other performance-critical programs: In order to optimize a program, the specifics of the platform architecture and the implementation of processors and networking become crucial.

Since abstraction leaks are unavoidable in programming -- even within block-based languages such as Scratch --, they have to be discussed in any case. Instead of tackling them one by one as separate exceptional cases, the literature discussed above suggests using this opportunity to work out the foundational idea of a multitier architecture and of the interconnectivity of computer systems.


\subsection{Abstractions in IDEs} \label{ssc_ides}

Integrated development environments used for programming offer a variety of different views on a program beyond its source code and its runtime output. The popular Visual Studio Code \eg offers step-by-step debugging with variables and the call stack listed through extensions \cite{Mic25}. This is mirrored in most other full-fledged \acp{IDE} such as PyCharm \cite{Jet25} or Eclipse \cite{Ecl25}. And while such \acp{IDE} even allow inspecting Python bytecode through appropriate extensions, the respective views are usually overwhelming for programming novices and thus rather targeted at professional developers than high school students.

As a remedy, several teaching-oriented \acp{IDE} have been developed, such as the Code with Mu \ac{IDE}, which offers a minimal command set and still allows runtime inspection \cite{Tol23}, or Thonny, which had the goal to visualize runtime concepts beyond what \acp{IDE} offered at the time \cite[p.\,119]{Ann15}: On the one hand, Thonny shows intermediary steps during expression evaluation. This demonstrates that statements are not evaluated in one go but indeed in a predetermined order operation by operation.\footnote{In professional \acp{IDE}, intermediary results are usually available by hovering over a specific operator with the order of evaluation being left to the user to determine.} On the other hand, Thonny visualizes recursion by showing code in a new pop-up for every function call, so that multiple recursive function calls lead to an equivalent number of visible pop-ups. Most other \acp{IDE} rather show a call stack in a separate view, which abstracts the call stack into a list of method names and line numbers.\footnote{As a compromise, \ac{GT} presented in \ref{sc_gt} displays the call stack as a list of expandable method sources with the call location highlighted.} Finally, Thonny distinguishes between values on the stack and values on the heap, showing the pointer to the heap as the value actually pushed on the stack and in a separate view the actual object on the heap at the given address. Thus, the Thonny \ac{IDE} sets out to and indeed nicely visualizes several concepts on lower runtime layers.

Jalalitabar and Wang \cite{Jal22} have assembled a list of tools targeted at visualizing some of these concepts outside of an \ac{IDE}. One notable such alternative approach is taken by Python Tutor \cite{Pyt25}, which combines a visualization of stack frame variable values as pointers and deconstructed objects.

As an additional \ac{IDE} feature, Sychev \cite{Syc21} suggests hints for syntax errors that show students a side-by-side view of their entered code and the corrected code with all the required transformations highlighted. They have implemented this feature for Moodle.

Bouvier \etal \cite{Bou24} ask for an extension of this: a view to show details about any form of error, helping students to better understand the issue at hand. In particular, they suggest including an \ac{LLM} assistant that can further help explain an error to a novice student. How effective such an assistant would be remains to be seen (see \ref{ssc_ct}).

Compared to \acp{IDE}, the web development consoles offered by modern web browsers also provide a variety of views of the various layers of the network stack. These views are, however, tailored to answer the most common questions of a web developer instead of providing a coherent overview of how the network layers interact.

A different introduction to lower system layers is suggested by Wörister and Knobelsdorf \cite{Woe24}, who also stick to block-based programming languages for manageability (see \ref{ssc_manageability}). They propose teaching lower-level concepts based on their newly developed block-based environment Blocksambler, whose block structure is translated live into pure text-based assembly language and whose debugging view exposes program counter, registers and memory. What is missing from Blocksambler is a way to directly connect it with Scratch or any other high-level language.

As an intermediary step between block-based and purely text-based languages, Kyfonidis \etal \cite{Kyf21} propose a frame-based interface that adds a colored background to blocks and statements. While this is meant to mimic a block-based view, it could just as well be used as an inline view of a program's \ac{AST}. Their solution for preventing parser errors does, however, rely on heavily restricting possible student input by having students first choose a statement type, inserting the respective template node, and have them fill in the blanks, which effectively introduces a new, two-stepped input mode.\footnote{The original proponents of frame-based editing, Kölling \etal \cite{Koe15} also noted as much.}

One kind of \ac{IDE} where a close connection to lower architectural layers would be expected are didactic \acp{IDE} targeted at microcontroller programming. While common microcontroller platforms such as Arduino or micro:bit are supported in many common \acp{IDE} (including didactic ones such as Thonny, mentioned above), specialized \acp{IDE} would be the ideal place to inspect the inner workings of a (virtual) machine. However, neither the official Arduino Lab for MicroPython editor\footnote{\emph{Cf.} \url{https://labs.arduino.cc/en/labs/micropython}, documented at \archivedurl{https://docs.arduino.cc/micropython/environment/code-editor/}.} nor micro:bit's Python editor\footnote{\emph{Cf.} \url{https://python.microbit.org/v/3}.} offer any additional views, not even matching Thonny's.
